
## AI for IoT and Mobile

- 2016, **ICLR**, [Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding](https://arxiv.org/pdf/1510.00149)

- 2016, **SenSys**, [Sparsification and Separation of Deep Learning Layers for Constrained Resource Inference on Wearables](http://discovery.ucl.ac.uk/1535346/1/main%20%283%29.pdf)

- 2017, **arXiv**, [Mobilenets: Efficient convolutional neural networks for mobile vision applications](https://arxiv.org/pdf/1704.04861)

- 2017, **SenSys**, [DeepIoT: Compressing Deep Neural Network Structures for Sensing Systems with a Compressor-Critic Framework](https://arxiv.org/pdf/1706.01215)

- 2018, **arXiv**, [Dynamic Channel Pruning: Feature Boosting and Suppression](https://arxiv.org/pdf/1810.05331)

- 2018, **arXiv**, [To compress or not to compress: Understanding the Interactions between Adversarial Attacks and Neural Network Compression](https://arxiv.org/pdf/1810.00208)

- 2018, **ECCV**, [PIRM Challenge on Perceptual Image Enhancement on Smartphones: Report](http://openaccess.thecvf.com/content_ECCVW_2018/papers/11133/Ignatov_PIRM_Challenge_on_Perceptual_Image_Enhancement_on_Smartphones_Report_ECCVW_2018_paper.pdf)

- 2018, **ICLR**, [Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training](https://arxiv.org/pdf/1712.01887.pdf?utm_campaign=nathan.ai%20newsletter&utm_medium=email&utm_source=Revue%20newsletter)

- 2018, **mobicom**, [FoggyCache : Cross-Device Approximate Computation Reuse](http://www.cs.yale.edu/homes/guo-peizhen/files/foggycache-mobicom18.pdf)

- 2018, **SenSys**, [FastDeepIoT: Towards Understanding and Optimizing Neural Network Execution Time on Mobile and Embedded Devices](https://arxiv.org/pdf/1809.06970)

- 2019, **arXiv**, [Adversarially Robust Distillation](https://arxiv.org/pdf/1905.09747)

- 2019, **arXiv**, [Characterizing the Deep Neural Networks Inference Performance of Mobile Applications](https://arxiv.org/pdf/1909.04783)

- 2019, **arXiv**, [Defensive Quantization: When Efficiency Meets Robustness](https://arxiv.org/pdf/1904.08444)

- 2019, **arXiv**, [Impact of Low-bitwidth Quantization on the Adversarial Robustness for Embedded Neural Networks](https://arxiv.org/pdf/1909.12741)

- 2019, **arXiv**, [On-Device Neural Net Inference with Mobile GPUs](https://arxiv.org/pdf/1907.01989)

- 2019, **arXiv**, [Robust Sparse Regularization: Simultaneously Optimizing Neural Network Robustness and Compactness](https://arxiv.org/pdf/1905.13074)

- 2019, **arXiv**, [Understanding Adversarial Robustness: The Trade-off between Minimum and Average Margin](https://arxiv.org/pdf/1907.11780)

- 2019, **HPCA**, [Machine Learning at Facebook: Understanding Inference at the Edge](https://research.fb.com/wp-content/uploads/2018/12/Machine-Learning-at-Facebook-Understanding-Inference-at-the-Edge.pdf)

- 2019, **ICCV**, [Adversarial Robustness vs. Model Compression, or Both](http://openaccess.thecvf.com/content_ICCV_2019/papers/Ye_Adversarial_Robustness_vs._Model_Compression_or_Both_ICCV_2019_paper.pdf)

- 2019, **WWW**, [A First Look at Deep Learning Apps on Smartphones](https://dl.acm.org/citation.cfm?id=3313591)

## Attacks and Defenses

### Adversarial Examples

#### Attacks

- 2017, **S&P**, [Towards Evaluating the Robustness of Neural Networks](https://arxiv.org/pdf/1608.04644)

- 2018, **KDD**, [Adversarial Attacks on Neural Networks for Graph Data](https://arxiv.org/pdf/1805.07984)

- 2018, **USENIX**, [With Great Training Comes Great Vulnerability: Practical Attacks against Transfer Learning](https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-wang.pdf)

- 2019, **arXiv**, [Privacy Risks of Securing Machine Learning Models against Adversarial Examples](https://arxiv.org/pdf/1905.10291)

- 2019, **arXiv**, [Stateful Detection of Black-Box Adversarial Attacks](https://arxiv.org/pdf/1907.05587)

- 2020, **USENIX**, [Hybrid Batch Attacks: Finding Black-box Adversarial Examples with Limited Queries](https://arxiv.org/pdf/1908.07000)

#### Defenses

- 2016, **S&P**, [Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks](https://arxiv.org/pdf/1511.04508)

- 2018, **arXiv**, [The Taboo Trap: Behavioural Detection of Adversarial Samples](https://arxiv.org/pdf/1811.07375)

- 2019, **arXiv**, [Defending Against Misclassification Attacks in Transfer Learning](https://arxiv.org/pdf/1908.11230)

- 2019, **arXiv**, [Sitatapatra: Blocking the Transfer of Adversarial Samples](https://arxiv.org/pdf/1901.08121)

- 2019, **arXiv**, [Using Honeypots to Catch Adversarial Attacks on Neural Networks](https://arxiv.org/pdf/1904.08554)

### Backdoor

#### Attacks

- 2018, **arXiv**, [How To Backdoor Federated Learning](https://arxiv.org/pdf/1807.00459)

- 2018, **CCS**, [Model-Reuse Attacks on Deep Learning Systems](https://arxiv.org/pdf/1812.00483)

- 2019, **arXiv**, [Bypassing Backdoor Detection Algorithms in Deep Learning](https://arxiv.org/pdf/1905.13409)

- 2019, **arXiv**, [Invisible Backdoor Attacks Against Deep Neural Networks](https://arxiv.org/pdf/1909.02742)

- 2019, **CCS**, [Regula Sub-rosa: Latent Backdoor Attacks on Deep Neural Networks](https://arxiv.org/pdf/1905.10447)

#### Defenses

- 2018, **arXiv**, [Detecting Backdoor Attacks on Deep Neural Networks by Activation Clustering](https://arxiv.org/pdf/1811.03728)

- 2018, **RAID**, [Fine-Pruning Defending Against Backdooring Attacks on Deep Neural Network](https://arxiv.org/pdf/1805.12185)

- 2019, **arXiv**, [TABOR: A Highly Accurate Approach to Inspecting and Restoring Trojan Backdoors in AI Systems](https://arxiv.org/pdf/1908.01763)

- 2019, **NeurIPS**, [Defending Neural Backdoors via Generative Distribution Modeling](https://arxiv.org/pdf/1910.04749)

- 2019, **S&P**, [Neural cleanse: Identifying and mitigating backdoor attacks in neural networks](https://people.cs.vt.edu/vbimal/publications/backdoor-sp19.pdf)

### Inference

#### Attacks

- 2017, **S&P**, [Membership Inference Attacks Against Machine Learning Models](https://arxiv.org/pdf/1610.05820)

- 2018, **CCS**, [Property Inference Attacks on Fully Connected Neural Networks using Permutation Invariant Representations](http://youngwei.com/pdf/PermuteInvariance.pdf)

- 2019, **S&P**, [Comprehensive Privacy Analysis of Deep Learning: Passive and Active White-box Inference Attacks against Centralized and Federated Learning](https://ieeexplore.ieee.org/abstract/document/8835245/)

#### Defenses

- 2018, **arXiv**, [PRIVADO: Practical and Secure DNN Inference with Enclaves](http://adsabs.harvard.edu/abs/2018arXiv181000602G)

- 2018, **arXiv**, [YerbaBuena: Securing Deep Learning Inference Data via Enclave-based Ternary Model Partitioning](https://www.researchgate.net/profile/Ankita_Lamba/publication/326171835_Securing_Input_Data_of_Deep_Learning_Inference_Systems_via_Partitioned_Enclave_Execution/links/5b75c09092851ca65064df4e/Securing-Input-Data-of-Deep-Learning-Inference-Systems-via-Partitioned-Enclave-Execution.pdf)

- 2019, **CCS**, [MemGuard: Defending against Black-Box Membership Inference Attacks via Adversarial Examples](https://arxiv.org/pdf/1909.10594)

- 2019, **mobicom**, [Occlumency: Privacy-preserving Remote Deep-learning Inference Using SGX](https://dl.acm.org/citation.cfm?id=3345447)

- 2019, **S&P**, [Certified Robustness to Adversarial Examples with Differential Privacy](https://arxiv.org/pdf/1802.03471)

- 2019, **SOSP**, [Privacy accounting and quality control in the sage differentially private ML platform](https://arxiv.org/pdf/1909.01502)

### Poisoning

#### Defenses

- 2019, **arXiv**, [Robust Graph Neural Network Against Poisoning Attacks via Transfer Learning](https://arxiv.org/pdf/1908.07558)

## Interpretability and Attacks to New Scenario

- 2019, **arXiv**, [Deep Leakage from Gradients](https://arxiv.org/pdf/1906.08935)

- 2020, **USENIX**, [Interpretable Deep Learning under Fire](https://arxiv.org/pdf/1812.00891)

## SGX and TrustZone

- 2017, **ICLR**, [SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and less than 0.5MB model size](https://arxiv.org/pdf/1602.07360)

- 2018, **arXiv**, [PRIVADO: Practical and Secure DNN Inference with Enclaves](http://adsabs.harvard.edu/abs/2018arXiv181000602G)

- 2018, **arXiv**, [StreamBox-TZ: Secure Stream Analytics at the Edge with TrustZone](https://www.usenix.org/system/files/atc19-park-heejin.pdf)

- 2018, **arXiv**, [YerbaBuena: Securing Deep Learning Inference Data via Enclave-based Ternary Model Partitioning](https://www.researchgate.net/profile/Ankita_Lamba/publication/326171835_Securing_Input_Data_of_Deep_Learning_Inference_Systems_via_Partitioned_Enclave_Execution/links/5b75c09092851ca65064df4e/Securing-Input-Data-of-Deep-Learning-Inference-Systems-via-Partitioned-Enclave-Execution.pdf)

- 2019, **arXiv**, [Let the Cloud Watch Over Your IoT File Systems](https://arxiv.org/pdf/1902.06327)

- 2019, **mobicom**, [Occlumency: Privacy-preserving Remote Deep-learning Inference Using SGX](https://dl.acm.org/citation.cfm?id=3345447)

## Survey

- 2017, **arXiv**, [A Survey of Model Compression and Acceleration for Deep Neural Networks](https://arxiv.org/pdf/1710.09282)

- 2018, **arXiv**, [A Survey of Machine and Deep Learning Methods for Internet of Things (IoT) Security](https://arxiv.org/pdf/1807.11023)

- 2018, **ECCV**, [AI Benchmark: Running Deep Neural Networks on Android Smartphones](http://openaccess.thecvf.com/content_ECCVW_2018/papers/11133/Ignatov_AI_Benchmark_Running_Deep_Neural_Networks_on_Android_Smartphones_ECCVW_2018_paper.pdf)

- 2019, **arXiv**, [AI Benchmark: All About Deep Learning on Smartphones in 2019](https://arxiv.org/pdf/1910.06663)

- 2019, **arXiv**, [Edge Intelligence: Paving the Last Mile of Artificial Intelligence with Edge Computing](https://arxiv.org/pdf/1905.10083)

- 2019, **TNN&LS**, [Adversarial Examples: Attacks and Defenses for Deep Learning](https://arxiv.org/pdf/1712.07107)
